{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Triple Stacked LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fi64aA0FFxcS",
        "outputId": "fa26823c-d8d0-438c-c83d-974e0221813d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JUValOzcHtEK"
      },
      "source": [
        "#Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab_type": "code",
        "id": "_Jpu8qLEFxcY",
        "outputId": "a8e264fc-5ac7-4bd7-99d5-f3eb32036ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVakjZ3oICgx"
      },
      "source": [
        "#Reading the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wnK5o4Z1Fxcj",
        "outputId": "1938f059-156c-4bc2-c8b2-f171db9be322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "data=pd.read_csv(\"/content/gdrive/My Drive/amazon-fine-food-reviews/Reviews.csv\",nrows=100000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kGNQKvCaISIn"
      },
      "source": [
        "# Drop Duplicates and NA values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cjul88oOFxcr",
        "colab": {}
      },
      "source": [
        "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)#dropping na"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r0xLYACiFxdJ"
      },
      "source": [
        "#Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0s6IY-x2FxdL",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XZr-u3OEFxdT",
        "outputId": "b39270a2-e223-404d-85cf-1f4e02a4b254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk \n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"html.parser\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A2QAeCHWFxdY",
        "colab": {}
      },
      "source": [
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GsRXocxoFxd-",
        "colab": {}
      },
      "source": [
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L1zLpnqsFxey",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sYK390unFxfA",
        "colab": {}
      },
      "source": [
        "#Drop empty rows\n",
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MdF76AHHFxgw",
        "outputId": "b68538c8-6e93-45f1-a6ff-b90e8326c7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "#Understanding the distribution of the sequences\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j9MZeJIsptJ+AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZKD5VOWqFxhC",
        "colab": {}
      },
      "source": [
        "max_text_len=30\n",
        "max_summary_len=8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yY0tEJP0FxhI",
        "colab": {}
      },
      "source": [
        "#select the reviews and summaries whose length falls below max_text_len and max_summary_len\n",
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EwLUH78CFxhg",
        "colab": {}
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RakakKHcFxhl",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vq1mqyOHOtIl"
      },
      "source": [
        "\n",
        "#Text Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oRHTgX6hFxhq",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RzvLwYL_PDcx"
      },
      "source": [
        "#Rarewords and its Coverage\n",
        "\n",
        "Let us look at the proportion rare words and its total coverage in the entire text\n",
        "\n",
        "Here, I am defining the threshold to be 4 which means word whose count is below 4 is considered as a rare word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y8KronV2Fxhx",
        "outputId": "f24ee0b8-8ab4-4069-f319-711e25ec3949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 66.12339930151339\n",
            "Total Coverage of rare words: 2.953684513790566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "So-J-5kzQIeO"
      },
      "source": [
        "\n",
        "* **tot_cnt** gives the size of vocabulary (which means every unique words in the text)\n",
        " \n",
        "*   **cnt** gives me the no. of rare words whose count falls below threshold\n",
        "\n",
        "*  **tot_cnt - cnt** gives me the top most common words \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J2giEsF3Fxh3",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eRHqyBkBFxiJ",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yzE5OiRLFxiM",
        "outputId": "5a4a82cf-b687-4179-b0a6-0c8f71d512dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 78.12740675541863\n",
            "Total Coverage of rare words: 5.392615517489563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-fswLvIgFxiR",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kZ-vW82sFxih",
        "colab": {}
      },
      "source": [
        "#deleting redundant rows i.e.,with no summary\n",
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cx5NISuMFxik",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wOtlDcthFxip"
      },
      "source": [
        "# Model building\n",
        "3 stacked LSTM for the encoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zXef38nBFxir",
        "outputId": "23a934fb-a0ae-483f-c331-c36fa8b9746a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        }
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 30, 100)      844000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    198900      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 1989)   1195389     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,823,389\n",
            "Trainable params: 4,823,389\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lwfi1Fm8Fxiz",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s-A3J92MUljB",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ETnPzA4OFxi3",
        "outputId": "28f708c8-9873-4427-c422-75d06b071263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        }
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 41346 samples, validate on 4588 samples\n",
            "Epoch 1/50\n",
            "41346/41346 [==============================] - 98s 2ms/sample - loss: 2.8216 - val_loss: 2.5735\n",
            "Epoch 2/50\n",
            "41346/41346 [==============================] - 90s 2ms/sample - loss: 2.5130 - val_loss: 2.4671\n",
            "Epoch 3/50\n",
            "41346/41346 [==============================] - 90s 2ms/sample - loss: 2.3675 - val_loss: 2.3095\n",
            "Epoch 4/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 2.2623 - val_loss: 2.2380\n",
            "Epoch 5/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 2.1930 - val_loss: 2.2030\n",
            "Epoch 6/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 2.1416 - val_loss: 2.1591\n",
            "Epoch 7/50\n",
            "41346/41346 [==============================] - 90s 2ms/sample - loss: 2.1006 - val_loss: 2.1376\n",
            "Epoch 8/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 2.0639 - val_loss: 2.1232\n",
            "Epoch 9/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 2.0321 - val_loss: 2.0993\n",
            "Epoch 10/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 2.0017 - val_loss: 2.1137\n",
            "Epoch 11/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 1.9758 - val_loss: 2.0902\n",
            "Epoch 12/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 1.9495 - val_loss: 2.0629\n",
            "Epoch 13/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 1.9255 - val_loss: 2.0528\n",
            "Epoch 14/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 1.9050 - val_loss: 2.0527\n",
            "Epoch 15/50\n",
            "41346/41346 [==============================] - 90s 2ms/sample - loss: 1.8857 - val_loss: 2.0577\n",
            "Epoch 16/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 1.8647 - val_loss: 2.0504\n",
            "Epoch 17/50\n",
            "41346/41346 [==============================] - 90s 2ms/sample - loss: 1.8471 - val_loss: 2.0560\n",
            "Epoch 18/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 1.8287 - val_loss: 2.0413\n",
            "Epoch 19/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 1.8119 - val_loss: 2.0388\n",
            "Epoch 20/50\n",
            "41346/41346 [==============================] - 89s 2ms/sample - loss: 1.7942 - val_loss: 2.0379\n",
            "Epoch 21/50\n",
            "41346/41346 [==============================] - 88s 2ms/sample - loss: 1.7780 - val_loss: 2.0476\n",
            "Epoch 22/50\n",
            "41346/41346 [==============================] - 88s 2ms/sample - loss: 1.7655 - val_loss: 2.0539\n",
            "Epoch 00022: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tDTNLAURFxjE",
        "outputId": "e024a909-e788-4adc-e8c2-41500b36f255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#plotting\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sBX0zZnOFxjW",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eM_nU_VvFxjq"
      },
      "source": [
        "# Inference\n",
        "\n",
        "Set up the inference for the encoder and decoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9QkrNV-4Fxjt",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6f6TTFnBFxj6",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aAUntznIFxj9",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe3Tm3dH1RRC",
        "colab_type": "text"
      },
      "source": [
        "#Evaluation\n",
        "Evaluating the model using Rogue score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rehY5OIqhEtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "totalReviews = len(y_val)\n",
        "listOfReferences = [seq2summary(y_val[i]) for i in range(totalReviews)]\n",
        "listOfHypothesis = [decode_sequence(x_val[i].reshape(1,max_text_len)) for i in range(totalReviews)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogaZQNt-hGvo",
        "colab_type": "code",
        "outputId": "bb12bad7-9dc9-4209-a669-0cf3de27409c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!pip3 install rouge\n",
        "import rouge\n",
        "r = rouge.Rouge()\n",
        "r.get_scores(listOfHypothesis, listOfReferences, avg=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/63/ac/b93411318529980ab7f41e59ed64ec3ffed08ead32389e29eb78585dd55d/rouge-0.3.2-py3-none-any.whl\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-0.3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge-1': {'f': 0.13345744024742476,\n",
              "  'p': 0.1697762278407442,\n",
              "  'r': 0.12269792834308949},\n",
              " 'rouge-2': {'f': 0.024954678013155592,\n",
              "  'p': 0.030496222028480086,\n",
              "  'r': 0.023477913397268232},\n",
              " 'rouge-l': {'f': 0.12003865747649718,\n",
              "  'p': 0.16916957279860526,\n",
              "  'r': 0.12231442271764838}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}